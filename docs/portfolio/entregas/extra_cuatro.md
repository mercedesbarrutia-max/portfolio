---
title: "Tarea Extra ‚Äî Transformaci√≥n Box‚ÄìCox y Demostraci√≥n de Data Leakage"
date: 2025-10-12
---

# Tarea Extra ‚Äî Transformaci√≥n Box‚ÄìCox y Demostraci√≥n de Data Leakage

## Contexto
Como trabajo independiente, como se ped√≠a en la tarea 7 de la UT2 se profundiz√≥ en un conceptos clave de la ingenier√≠a de datos que es el uso de la transformaci√≥n Box‚ÄìCox para normalizar variables sesgadas y mejorar la calidad del dataset.

---

## Objetivos

- Aplicar y justificar el uso de la transformaci√≥n **Box‚ÄìCox** sobre variables num√©ricas sesgadas.  
- Comparar la distribuci√≥n de los datos antes y despu√©s de la transformaci√≥n.  
- Implementar una validaci√≥n cruzada sin fuga de datos (anti-leakage).  
- Comprobar la diferencia entre escalar correctamente y hacerlo de forma incorrecta.  

---

## Desarrollo

### üîπ Transformaci√≥n Box‚ÄìCox
La transformaci√≥n **Box‚ÄìCox** se aplic√≥ sobre las variables `SalePrice`, `Lot Area`, `Misc Val` y `Total Bsmt SF` utilizando `PowerTransformer(method='box-cox')`.  

Previamente se implement√≥ un **transformador personalizado** (`PositiveShift`) para desplazar los valores a positivos y as√≠ permitir el uso correcto de Box‚ÄìCox. Debido a que este transformador no funciona com valores nulos o faltantes.

```python
from sklearn.base import BaseEstimator, TransformerMixin

class PositiveShift(BaseEstimator, TransformerMixin):
    def fit(self, X, y=None):
        self.shift_ = np.abs(np.min(X, axis=0)) + 1
        return self
    def transform(self, X):
        return X + self.shift_
```

Esta estrategia evit√≥ errores de validaci√≥n y permiti√≥ incluir la transformaci√≥n dentro de un pipeline reproducible, manteniendo las buenas pr√°cticas de ingenier√≠a de datos.

# Resultados

| Variable      | Skew Antes | Skew Despu√©s (Box‚ÄìCox) | Mejora |
| :------------ | :--------: | :--------------------: | :----: |
| SalePrice     |    1.44    |          0.07          |    ‚úÖ   |
| Lot Area      |    12.82   |          0.10          |    ‚úÖ   |
| Misc Val      |    22.00   |          5.05          |    ‚úÖ   |
| Total Bsmt SF |    1.16    |          0.11          |    ‚úÖ   |

Las distribuciones se volvieron mucho m√°s sim√©tricas, reduciendo la asimetr√≠a y la varianza. Los histogramas evidenciaron una normalizaci√≥n clara y la reducci√≥n del efecto de los outliers.


## Evidencias
* Notebook: **[06 - Feature Scaling Pipeline.ipynb](cinco.ipynb)**  
* Gr√°ficos: 
![distribuci√≥n](results/entregaextracuatro.png) 


## Reflexi√≥n
La pr√°ctica me permiti√≥ ver en la pr√°ctica c√≥mo las decisiones de preprocesamiento impactan directamente en la calidad y confiabilidad de los modelos.
Box‚ÄìCox result√≥ muy √∫til para estabilizar la varianza en variables positivas y reducir la influencia de valores extremos.

## Preguntas gu√≠a

* ¬øCu√°ndo recomendar√≠as tu transformador?

    Cuando las variables son positivas y tienen mucha asimetr√≠a. Box‚ÄìCox ayuda a normalizar y reduce el impacto de los outliers sin perder informaci√≥n.

* ¬øCu√°ndo no lo usar√≠as?

    Si hay ceros o negativos, o en modelos basados en √°rboles, donde la forma de la distribuci√≥n no importa tanto.

* ¬øEn qu√© casos supera a los scalers tradicionales?
    
    Cuando el problema no es solo la escala, sino la forma de la distribuci√≥n. Box‚ÄìCox ajusta la simetr√≠a del dato, mientras los scalers solo cambian su rango o media.

# Conclusiones

La transformaci√≥n Box‚ÄìCox demostr√≥ ser una herramienta muy buena y √∫til para mejorar la calidad estad√≠stica del dataset, logrando distribuciones m√°s estables y modelos m√°s confiables.
A su vez, es importante respetar el orden correcto de preprocesamiento y el uso de pipelines. Ambas cosas complementan la formaci√≥n en ingenier√≠a de datos, mostrando que los buenos resultados dependen de los algoritmos, la preparaci√≥n y validaci√≥n de los datos.